import pandas as pd
import numpy as np
from pathlib import Path
import json
from datetime import datetime

class FlightSamplingPipeline:
    def __init__(self, input_parquet_dir, output_dir, year=2023):
        self.input_dir = Path(input_parquet_dir)
        self.output_dir = Path(output_dir)
        self.year = year
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # --- Cáº¤U HÃŒNH THEO KHUNG LÃ THUYáº¾T ---
        
        # 1. Äá»‹nh má»©c máº«u (Quota Allocation) - Ref: Section 2.2
        self.QUOTAS = {
            'Severe':   {'min': 60,  'max': 99999, 'count': 50},  # > 60 mins
            'Moderate': {'min': 30,  'max': 60,    'count': 100}, # 30 - 60 mins
            'Minor':    {'min': 0,   'max': 30,    'count': 150}, # 0 - 30 mins
            'OnTime':   {'min': -999,'max': 0,     'count': 200}  # <= 0 mins
        }
        
        # 2. Trá»ng sá»‘ Æ°u tiÃªn (Weighting Weights) - Ref: Section 3.2
        self.WEIGHTS = {
            'carrier': 2.0,  # Æ¯u tiÃªn hÃ£ng lá»›n
            'airport': 1.5,  # Æ¯u tiÃªn sÃ¢n bay lá»›n
            'peak': 1.0,     # Æ¯u tiÃªn giá» cao Ä‘iá»ƒm
            'base': 1.0      # Äiá»ƒm cÆ¡ báº£n
        }
        
        # Giá» cao Ä‘iá»ƒm (Peak Hours): 6-9h vÃ  16-19h
        self.PEAK_HOURS = list(range(6, 10)) + list(range(16, 20))
        
        # CÃ¡c biáº¿n lÆ°u trá»¯ Top Carrier/Airport (sáº½ Ä‘Æ°á»£c fill khi cháº¡y analyze)
        self.top_carriers = []
        self.top_airports = []

    def _analyze_population_characteristics(self):
        """
        BÆ°á»›c 1: QuÃ©t nhanh dá»¯ liá»‡u Ä‘á»ƒ xÃ¡c Ä‘á»‹nh Top Carriers vÃ  Top Airports.
        DÃ¹ng Ä‘á»ƒ tÃ­nh trá»ng sá»‘ chÃ­nh xÃ¡c.
        """
        print(f"ðŸ” [Phase 1] Analyzing Population (NÄƒm {self.year})...")
        
        # Äá»c máº«u nhanh (chá»‰ cáº§n láº¥y 1-2 thÃ¡ng Ä‘áº¡i diá»‡n hoáº·c Ä‘á»c metadata náº¿u cÃ³)
        # á»ž Ä‘Ã¢y ta Ä‘á»c thÃ¡ng 1 vÃ  thÃ¡ng 7 Ä‘á»ƒ Ä‘áº¡i diá»‡n mÃ¹a tháº¥p Ä‘iá»ƒm/cao Ä‘iá»ƒm
        sample_months = [1, 7]
        dfs = []
        
        for m in sample_months:
            p = self.input_dir / f"year={self.year}" / f"month={m:02d}"
            if p.exists():
                try:
                    # Chá»‰ Ä‘á»c cá»™t cáº§n thiáº¿t Ä‘á»ƒ nhanh
                    df = pd.read_parquet(p, columns=['OP_CARRIER', 'ORIGIN', 'DEST'])
                    dfs.append(df)
                except Exception as e:
                    print(f"  âš ï¸ Warning: KhÃ´ng Ä‘á»c Ä‘Æ°á»£c thÃ¡ng {m}: {e}")
        
        if not dfs:
            print("  âŒ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u máº«u. DÃ¹ng danh sÃ¡ch máº·c Ä‘á»‹nh.")
            return

        full_sample = pd.concat(dfs)
        
        # Láº¥y Top 10 HÃ£ng bay
        self.top_carriers = full_sample['OP_CARRIER'].value_counts().head(10).index.tolist()
        
        # Láº¥y Top 20 SÃ¢n bay (Origin + Dest)
        all_airports = pd.concat([full_sample['ORIGIN'], full_sample['DEST']])
        self.top_airports = all_airports.value_counts().head(20).index.tolist()
        
        print(f"  âœ… Identified {len(self.top_carriers)} Top Carriers & {len(self.top_airports)} Top Airports.")

    def _calculate_priority_score(self, df):
        """
        BÆ°á»›c 2: TÃ­nh Ä‘iá»ƒm Æ°u tiÃªn (Priority Score) cho tá»«ng dÃ²ng.
        CÃ´ng thá»©c: S = Base + w_carrier + w_airport + w_peak
        Ref: Section 3.2 Formula
        """
        # Khá»Ÿi táº¡o Ä‘iá»ƒm cÆ¡ báº£n
        scores = np.ones(len(df)) * self.WEIGHTS['base']
        
        # Cá»™ng Ä‘iá»ƒm HÃ£ng bay (Vectorized operation)
        if 'OP_CARRIER' in df.columns:
            scores += np.where(df['OP_CARRIER'].isin(self.top_carriers), self.WEIGHTS['carrier'], 0)
            
        # Cá»™ng Ä‘iá»ƒm SÃ¢n bay (Origin hoáº·c Dest náº±m trong top Ä‘á»u Ä‘Æ°á»£c cá»™ng)
        if 'ORIGIN' in df.columns and 'DEST' in df.columns:
            is_top_origin = df['ORIGIN'].isin(self.top_airports)
            is_top_dest = df['DEST'].isin(self.top_airports)
            # DÃ¹ng logic OR: Chá»‰ cáº§n 1 trong 2 lÃ  sÃ¢n bay lá»›n thÃ¬ Ä‘Æ°á»£c cá»™ng Ä‘iá»ƒm
            scores += np.where(is_top_origin | is_top_dest, self.WEIGHTS['airport'], 0)
            
        # Cá»™ng Ä‘iá»ƒm Giá» cao Ä‘iá»ƒm
        if 'DEP_TIME' in df.columns:
            # Chuyá»ƒn DEP_TIME (float/str) vá» giá» (int). VD: 630.0 -> 6
            dep_hour = pd.to_numeric(df['DEP_TIME'], errors='coerce').fillna(0).astype(int) // 100
            scores += np.where(np.isin(dep_hour, self.PEAK_HOURS), self.WEIGHTS['peak'], 0)
            
        return scores

    def _weighted_sampling(self, df, n_samples, random_state):
        """
        HÃ m core: Thá»±c hiá»‡n Weighted Random Sampling.
        Náº¿u dá»¯ liá»‡u Ã­t hÆ¡n n_samples -> Láº¥y háº¿t (khÃ´ng sinh thÃªm Ä‘á»ƒ trÃ¡nh fake data).
        """
        if len(df) == 0:
            return pd.DataFrame()
        
        if len(df) <= n_samples:
            return df  # Láº¥y háº¿t náº¿u khÃ´ng Ä‘á»§ (Oversampling tá»± nhiÃªn báº±ng cÃ¡ch giá»¯ nguyÃªn)
            
        # Normalization trá»ng sá»‘ Ä‘á»ƒ hÃ m sample hiá»ƒu
        weights = df['priority_score']
        if weights.sum() == 0:
            weights = None # Fallback vá» random thÆ°á»ng náº¿u weights lá»—i
            
        return df.sample(n=n_samples, weights=weights, random_state=random_state)

    def run_pipeline(self):
        print(f"\nðŸš€ [Phase 2] Starting Stratified Sampling Pipeline...")
        
        # 1. Cháº¡y phÃ¢n tÃ­ch trÆ°á»›c
        self._analyze_population_characteristics()
        
        all_samples = []
        stats = []

        # 2. Loop qua 12 thÃ¡ng (Stratified by Time)
        for month in range(1, 13):
            month_path = self.input_dir / f"year={self.year}" / f"month={month:02d}"
            
            if not month_path.exists():
                print(f"  âš ï¸ ThÃ¡ng {month:02d}: KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u.")
                continue
                
            print(f"  ðŸ“… Processing Month {month:02d}...", end=" ")
            
            try:
                # Äá»c dá»¯ liá»‡u thÃ¡ng
                df = pd.read_parquet(month_path)
                
                # Preprocessing cÆ¡ báº£n
                if 'ARR_DELAY' not in df.columns:
                    print("Skipping (Missing ARR_DELAY)")
                    continue
                
                df = df.dropna(subset=['ARR_DELAY'])
                
                # TÃ­nh Score
                df['priority_score'] = self._calculate_priority_score(df)
                
                month_collected = []
                
                # 3. Loop qua tá»«ng táº§ng Ä‘á»™ trá»… (Stratified by Severity)
                for label, criteria in self.QUOTAS.items():
                    # Filter dá»¯ liá»‡u theo Ä‘á»‹nh nghÄ©a táº§ng
                    mask = (df['ARR_DELAY'] > criteria['min']) & (df['ARR_DELAY'] <= criteria['max'])
                    subset = df[mask]
                    
                    # 4. Láº¥y máº«u cÃ³ trá»ng sá»‘ (Weighted Sampling)
                    sampled = self._weighted_sampling(
                        subset, 
                        n_samples=criteria['count'], 
                        random_state=42 + month # Seed thay Ä‘á»•i theo thÃ¡ng
                    )
                    
                    # GÃ¡n nhÃ£n Ä‘á»ƒ theo dÃµi sau nÃ y
                    sampled['DELAY_GROUP'] = label
                    sampled['SAMPLING_MONTH'] = month
                    
                    month_collected.append(sampled)
                    
                    # Log thá»‘ng kÃª
                    stats.append({
                        'Month': month,
                        'Group': label,
                        'Available': len(subset),
                        'Sampled': len(sampled)
                    })

                # Gá»™p máº«u thÃ¡ng
                month_final = pd.concat(month_collected)
                all_samples.append(month_final)
                print(f"âœ… OK (Selected {len(month_final)} rows)")
                
            except Exception as e:
                print(f"âŒ Error: {e}")

        # 5. Káº¿t há»£p vÃ  Xuáº¥t dá»¯ liá»‡u
        print(f"\nðŸ“¦ [Phase 3] Exporting Data...")
        if not all_samples:
            print("âŒ No data sampled!")
            return

        final_df = pd.concat(all_samples, ignore_index=True)
        
        # Clean up cá»™t táº¡m
        cols_to_drop = ['priority_score']
        final_df.drop(columns=[c for c in cols_to_drop if c in final_df.columns], inplace=True)
        
        # Save CSV
        output_file = self.output_dir / f"flight_data_sampled_{self.year}.csv"
        final_df.to_csv(output_file, index=False)
        
        # Save Report
        self._save_report(final_df, stats)
        
        print(f"ðŸŽ‰ Pipeline Completed Successfully!")
        print(f"   - Output: {output_file}")
        print(f"   - Total Rows: {len(final_df)}")

    def _save_report(self, df, stats):
        """LÆ°u bÃ¡o cÃ¡o thá»‘ng kÃª Ä‘á»ƒ Ä‘Æ°a vÃ o Ä‘á»“ Ã¡n"""
        report_file = self.output_dir / "sampling_report_v2.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("SAMPLING STRATEGY REPORT (THEORETICAL FRAMEWORK)\n")
            f.write("================================================\n\n")
            
            f.write("1. DATA DISTRIBUTION BY DELAY GROUP (QUOTA CHECK)\n")
            group_counts = df['DELAY_GROUP'].value_counts()
            total = len(df)
            for group, count in group_counts.items():
                f.write(f"   - {group}: {count} rows ({count/total:.1%})\n")
                
            f.write("\n2. COVERAGE CHECK\n")
            top_carrier_coverage = df['OP_CARRIER'].isin(self.top_carriers).mean()
            f.write(f"   - Top Carrier Presence: {top_carrier_coverage:.1%}\n")
            
            f.write("\n3. DETAILED LOG (MONTHLY)\n")
            f.write(f"{'Month':<6} | {'Group':<10} | {'Available':<10} | {'Sampled':<10}\n")
            f.write("-" * 45 + "\n")
            for s in stats:
                f.write(f"{s['Month']:<6} | {s['Group']:<10} | {s['Available']:<10} | {s['Sampled']:<10}\n")
        
        print(f"   - Report: {report_file}")

# --- MAIN EXECUTION ---
if __name__ == "__main__":
    # Sá»­a chá»¯ DA_AVD thÃ nh ADA cho Ä‘Ãºng vá»›i mÃ¡y cá»§a báº¡n
    INPUT_PATH = "D:/UEL/ADA/ADA-Flight-Delay/data/parquet/flights_weather"
    
    # Output giá»¯ nguyÃªn hoáº·c sá»­a láº¡i tÃ¹y Ã½
    OUTPUT_PATH = "D:/UEL/ADA/ADA-Flight-Delay/data/sampled"
    
    pipeline = FlightSamplingPipeline(INPUT_PATH, OUTPUT_PATH)
    pipeline.run_pipeline()